{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Sukhwinder9813/EmojiPredictionfromTweet/blob/master/EmojiPredictorfromTweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kAlEgX58utaq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "T3YAHQy8uyF6",
    "outputId": "46f02252-6db2-4ea8-cfd0-7be75d90fce1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\zhangkerou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\zhangkerou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\zhangkerou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\zhangkerou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\zhangkerou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\zhangkerou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\zhangkerou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\zhangkerou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\zhangkerou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\zhangkerou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\zhangkerou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\zhangkerou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\zhangkerou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\zhangkerou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\zhangkerou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\zhangkerou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\zhangkerou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\zhangkerou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\zhangkerou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N8gQ_7rVu1MO"
   },
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "13tvAmK9u2u3"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bx6Xigv0vQBz"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vEcGoQxlvUTt"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIfp3F_cvaN5"
   },
   "outputs": [],
   "source": [
    "x_train=data['TEXT'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gzVOlVCjvjzb"
   },
   "outputs": [],
   "source": [
    "y_train=data['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HCLT8jtsvn9V"
   },
   "outputs": [],
   "source": [
    "smoothtweets=[]\n",
    "stopper=set(stopwords.words('english'))\n",
    "for tweets in x_train:\n",
    "    words=tweets.split(\" \")\n",
    "    str = \"\"\n",
    "    for word in words:\n",
    "        if word[0] != \"@\" and word not in stopper:\n",
    "            if word[0] == \"#\":\n",
    "                word = word[1:]\n",
    "        str += word + \" \"\n",
    "    smoothtweets.append(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JY4h-9fJv1_e",
    "outputId": "598c2fc6-de56-4fcf-bd68-6dc43d2c7341"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Been friends since 7th grade. Look at us now we all following our dreams doing what we love and…\\n '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothtweets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1NNmPguWwXQ3"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', split=\" \", lower=True)\n",
    "tokenizer.fit_on_texts(smoothtweets)\n",
    "newsmoothtweets=[]\n",
    "newsmoothtweets=tokenizer.texts_to_sequences(smoothtweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "00D6AaRhwif5",
    "outputId": "8757f3f7-6218-43a3-92ed-83e1ea51e3de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 16, 65, 24, 430, 53, 44, 487, 375, 10, 10236, 213, 1047, 519, 10237]\n"
     ]
    }
   ],
   "source": [
    "print(newsmoothtweets[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oL7c1yQezR_k"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "X_train=sequence.pad_sequences(newsmoothtweets,maxlen=12,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5v_aKbOV1rrz"
   },
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Sequential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrWj-1nH1tmF"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mOGOXpNA4D5N"
   },
   "outputs": [],
   "source": [
    "Y_train=to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P5EixeLs4JM-",
    "outputId": "35353e64-4682-402d-b986-6bcb1f2e0c9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 20)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qrjrEZCg4LeZ",
    "outputId": "98685012-6b28-412b-b667-a5154ed4c8de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGB5mMMs4UH8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yGFFCq63BvcV"
   },
   "outputs": [],
   "source": [
    "wordembedd={}\n",
    "f=open('glove.6B.50d.txt',\"r\",encoding='utf-8')\n",
    "for line in f:\n",
    "  words=line.split()\n",
    "  word=words[0]\n",
    "  coefs=np.asarray(words[1:],dtype='float')\n",
    "  wordembedd[word]=coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eBNTC2uGB4N5"
   },
   "outputs": [],
   "source": [
    "def populate_weight_matrix(vocab, raw_embedding):\n",
    "    # Create weight matrix from pre-trained embeddings\n",
    "    vocab_size = len(vocab) + 1\n",
    "    weight_matrix = np.zeros((vocab_size, 50))\n",
    "    for word, i in vocab.items():\n",
    "        if word in raw_embedding:\n",
    "            weight_matrix[i] = raw_embedding[word]\n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQUFBebKDtMs"
   },
   "outputs": [],
   "source": [
    "vocab=tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "usY_gQmlDvrv"
   },
   "outputs": [],
   "source": [
    "len(vocab)\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-BlzRCNaDxQX"
   },
   "outputs": [],
   "source": [
    "weight_matrix=populate_weight_matrix(vocab,wordembedd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "rAT2YiKWD85D",
    "outputId": "c33b83e3-a93e-4a51-9b4a-b262287a6b2c"
   },
   "outputs": [],
   "source": [
    "weight_matrix[8]\n",
    "max_length = math.ceil(sum([len(s.split(\" \")) for s in smoothtweets])/len(smoothtweets))\n",
    "vocab_size=len(vocab)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(vocab_size,weight_matrix,max_length,X_train,Y_train,embed_dim=50,epochs=5,):\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab_size,embed_dim,weights=[weight_matrix],input_length=max_length,trainable=True,))\n",
    "    model.add(LSTM(128,dropout=0.2,return_sequences=True))\n",
    "    model.add(LSTM(128,dropout=0.2))\n",
    "    model.add(Dense(20,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(X_train,Y_train,epochs=epochs,batch_size=128,shuffle=True,validation_split=0.15)\n",
    "    model.evaluate(X_train,Y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-paysZAOEFVR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 13, 50)            4276550   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 13, 128)           91648     \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                2580      \n",
      "=================================================================\n",
      "Total params: 4,502,362\n",
      "Trainable params: 4,502,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"embedding_3_input:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 12).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"embedding_3_input:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 12).\n",
      "464/465 [============================>.] - ETA: 0s - loss: 2.5170 - accuracy: 0.2636WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"embedding_3_input:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 12).\n",
      "465/465 [==============================] - 22s 47ms/step - loss: 2.5169 - accuracy: 0.2637 - val_loss: 2.3075 - val_accuracy: 0.3061\n",
      "2188/2188 [==============================] - 9s 4ms/step - loss: 2.2687 - accuracy: 0.3214\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"embedding_3_input:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 12).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 9, 3, 3, 7, 5, 1, 9, 9, 9, 9, 9], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_training(vocab_size,weight_matrix,max_length,X_train,Y_train,)\n",
    "model.predict_classes(X_train[1:13])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "68iH6akNEXZm",
    "outputId": "fd844a78-018d-448b-e4ef-d68daf14b2e1"
   },
   "outputs": [],
   "source": [
    "def emoji_pred():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "sjAxyfXjFHDX",
    "outputId": "c14d0725-85b6-43e7-98b1-bcd4855e6648"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "XMfMfeZFFYFJ",
    "outputId": "745b45ac-feda-4077-cae8-15af0641246c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uW89zp7qLIPH",
    "outputId": "0a05d63e-7a06-442c-ea18-46e5c72cb273"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "s3swNlIBOKMl",
    "outputId": "30b17e35-e0a0-41fa-b5c1-a9a05635dd95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Story On Saturday 136 Collins Ave, Miami Beach, FL 33139 Ladies Contact Me To Join Me In my…\\n '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothtweets[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M44ksr8uOdux"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😂\n",
      "One favorite gyms FREE Fucking membership, get ass . Balboa Park\n",
      " \n",
      "😂\n",
      "Hanging guy today Thank great shoot filled plenty of…\n",
      " \n",
      "😍\n",
      "mood today Parkway North High School\n",
      " \n",
      "😍\n",
      "Chandelier Widener Library\n",
      " \n",
      "😂\n",
      "Sorry jump bandwagon. thisfilteriseverything Las…\n",
      " \n",
      "❤\n",
      "️ Princeton, New Jersey\n",
      " \n",
      "😂\n",
      "My main man Gladstone, Missouri\n",
      " \n",
      "😂\n",
      "Eat shit Irma ghostriotradio hurricaneirma irmanators goodforsprinkle pbr…\n",
      " \n",
      "❤\n",
      "Max went first aquarium trip went moving walkway. He amazing! ️ Check out…\n",
      " \n",
      "😍\n",
      "ikea fun me ... oh dam store, like disney interior architect's IKEA\n",
      " \n",
      "😂\n",
      "It's like I blinked 2 years flew Short Pump Town Center\n",
      " \n",
      "😂\n",
      "When moment meet future husband!!! marlonovershawn teammarlon Stress…\n",
      " \n",
      "😂\n",
      "We working hard today McDonald's 16827 Marsh Rd\n",
      " \n",
      "🔥\n",
      "\"No Flocking\" shot coming soon! LSV2 available datpiff freestyle…\n",
      " \n",
      "🔥\n",
      "Dj Ivan G! One Mixer, One Man, One Dj, That Rocks The Party! Always Mixes for…\n",
      " \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "emoji_map=pd.read_csv('Mapping.csv')\n",
    "data_test = pd.read_csv('Test.csv')\n",
    "x_test = data_test['TEXT'].values\n",
    "\n",
    "#pred_corpus_test=corpus_pre(x_test)\n",
    "\n",
    "smoothTESTtweets=[]\n",
    "stopper=set(stopwords.words('english'))\n",
    "for tweets in x_test:\n",
    "    words=tweets.split(\" \")\n",
    "    str = \"\"\n",
    "    for word in words:\n",
    "        if word[0] != \"@\" and word not in stopper:\n",
    "            if word[0] == \"#\":\n",
    "                word = word[1:]\n",
    "            str += word + \" \"\n",
    "    smoothTESTtweets.append(str)\n",
    "\n",
    "def tokenize(pred_corpus, l1):\n",
    "    seqed_corpus = tokenizer.texts_to_sequences(pred_corpus)  # 将数据集序列化，就是把句中每一个单词编号\n",
    "    X_out = sequence.pad_sequences(seqed_corpus, maxlen=l1, padding='post')  # 填充与截断序列，就是使得每句话对应的序列长度都是'maxlen'\n",
    "    return X_out\n",
    "\n",
    "tokenize(smoothTESTtweets, 12)\n",
    "label_test=model.predict_classes(X_test)\n",
    "\n",
    "for i in range(20,35,1):\n",
    "    print(emoji_map['emoticons'][label_test[i]])\n",
    "    print(smoothTESTtweets[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "colab_type": "code",
    "id": "NL1_joZFOkjm",
    "outputId": "a1e22a1e-915b-4661-c6b6-8b407674139a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>emoticons</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>😜</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>📸</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>😍</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>😂</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>😉</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>🎄</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>📷</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>🔥</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>😘</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>❤</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>😁</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>🇺🇸</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>☀</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>✨</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>💙</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>💕</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>😎</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>😊</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>💜</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>💯</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 emoticons  number\n",
       "0            0         😜       0\n",
       "1            1         📸       1\n",
       "2            2         😍       2\n",
       "3            3         😂       3\n",
       "4            4         😉       4\n",
       "5            5         🎄       5\n",
       "6            6         📷       6\n",
       "7            7         🔥       7\n",
       "8            8         😘       8\n",
       "9            9         ❤       9\n",
       "10          10         😁      10\n",
       "11          11        🇺🇸      11\n",
       "12          12         ☀      12\n",
       "13          13         ✨      13\n",
       "14          14         💙      14\n",
       "15          15         💕      15\n",
       "16          16         😎      16\n",
       "17          17         😊      17\n",
       "18          18         💜      18\n",
       "19          19         💯      19"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_kZ4aFw5OmsC",
    "outputId": "01c1a461-0231-4abb-f568-d42446ee03f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data['Label'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RGn4ZSs7Pk5S"
   },
   "outputs": [],
   "source": [
    "#df3=pd.read_csv('Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "q7o7dypwP2EX",
    "outputId": "197825c6-fae4-4287-8d0b-5b1ed1b17992"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thought this was cool...#Repost (get_repost)・・...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Happy 4th! Corte madera parade. #everytownusa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Luv. Or at least something close to it. @ Unio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>There's a slice of pie under that whipped crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>#thankyou for your thank you We adore you both...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id                                               TEXT\n",
       "0           0   0  Thought this was cool...#Repost (get_repost)・・...\n",
       "1           1   1  Happy 4th! Corte madera parade. #everytownusa ...\n",
       "2           2   2  Luv. Or at least something close to it. @ Unio...\n",
       "3           3   3  There's a slice of pie under that whipped crea...\n",
       "4           5   5  #thankyou for your thank you We adore you both..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4NmqscTP32m"
   },
   "outputs": [],
   "source": [
    "#xtest=df3['TEXT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZszR1hgVP998"
   },
   "outputs": [],
   "source": [
    "# smoothTESTtweets=[]\n",
    "# stopper=set(stopwords.words('english'))\n",
    "# for tweets in xtest:\n",
    "#   words=tweets.split(\" \")\n",
    "#   str = \"\"\n",
    "#   for word in words:\n",
    "#       if word[0] != \"@\" and word not in stopper:\n",
    "#           if word[0] == \"#\":\n",
    "#               word = word[1:]\n",
    "#           str += word + \" \"\n",
    "#   smoothTESTtweets.append(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nUkufJK2RBR5"
   },
   "outputs": [],
   "source": [
    "newsmoothtweets=tokenizer.texts_to_sequences(smoothTESTtweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mxIlFe6fRMP8",
    "outputId": "8a93d10d-22ca-44bf-bdc0-ef222bebc7ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1240, 163, 1132, 462, 842, 24, 776, 523, 1621, 351]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsmoothtweets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I5LAMTzoROui"
   },
   "outputs": [],
   "source": [
    "x_test=sequence.pad_sequences(newsmoothtweets,maxlen=12,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "MF4pWqdbRY0q",
    "outputId": "e3b9d441-3058-45e7-f760-cc20407413ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 716, 7386, 1682, 5295,  770,  126, 6904,    0,    0,    0,    0,\n",
       "          0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "srnw-__dRc4k"
   },
   "outputs": [],
   "source": [
    "label_test=model.predict_classes(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "colab_type": "code",
    "id": "xZBuAGupjPbS",
    "outputId": "143d0fbf-37a0-4cbe-9e47-08f0261a8441"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😂\n",
      "One favorite gyms FREE Fucking membership, get ass . Balboa Park\n",
      " \n",
      "😂\n",
      "Hanging guy today Thank great shoot filled plenty of…\n",
      " \n",
      "😍\n",
      "mood today Parkway North High School\n",
      " \n",
      "😍\n",
      "Chandelier Widener Library\n",
      " \n",
      "😂\n",
      "Sorry jump bandwagon. thisfilteriseverything Las…\n",
      " \n",
      "❤\n",
      "️ Princeton, New Jersey\n",
      " \n",
      "😂\n",
      "My main man Gladstone, Missouri\n",
      " \n",
      "😂\n",
      "Eat shit Irma ghostriotradio hurricaneirma irmanators goodforsprinkle pbr…\n",
      " \n",
      "❤\n",
      "Max went first aquarium trip went moving walkway. He amazing! ️ Check out…\n",
      " \n",
      "😍\n",
      "ikea fun me ... oh dam store, like disney interior architect's IKEA\n",
      " \n",
      "😂\n",
      "It's like I blinked 2 years flew Short Pump Town Center\n",
      " \n",
      "😂\n",
      "When moment meet future husband!!! marlonovershawn teammarlon Stress…\n",
      " \n",
      "😂\n",
      "We working hard today McDonald's 16827 Marsh Rd\n",
      " \n",
      "🔥\n",
      "\"No Flocking\" shot coming soon! LSV2 available datpiff freestyle…\n",
      " \n",
      "🔥\n",
      "Dj Ivan G! One Mixer, One Man, One Dj, That Rocks The Party! Always Mixes for…\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for i in range(20,35,1):\n",
    "  print(emoji_map['emoticons'][label_test[i]])\n",
    "  print(smoothTESTtweets[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Um3AlDbTRi70",
    "outputId": "1b6306e6-6d4d-4152-bbea-d3c74536215d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Luv. Or least something close it. Union Hill, Richmond, Virginia\\n '"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothTESTtweets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "KksJU8qrRsT0",
    "outputId": "8653299a-e82c-42da-ae83-3445324ba790"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Au64K86R7Xw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMh8+va2lKBaCOYCHgJ0Na+",
   "include_colab_link": true,
   "name": "EmojiPredictorfromTweets.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
